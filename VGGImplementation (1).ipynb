{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OpU1FZIsvAGm"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "keras.backend.set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "# Custom metrics\n",
    "\n",
    "# f1 score\n",
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    # tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sy6krHoYvAGp"
   },
   "outputs": [],
   "source": [
    "def vgg16_model(img_rows, img_cols, channel, num_classes):\n",
    "    \"\"\"VGG 16 Model for Keras\n",
    "    Model Schema is based on \n",
    "    https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3\n",
    "    ImageNet Pretrained Weights \n",
    "    https://drive.google.com/file/d/0Bz7KyqmuGsilT0J5dmRCM0ROVHc/view?usp=sharing\n",
    "    Parameters:\n",
    "      img_rows, img_cols - resolution of inputs\n",
    "      channel - 1 for grayscale, 3 for color \n",
    "      num_classes - number of categories for our classification task\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    #1\n",
    "    model.add(ZeroPadding2D((1, 1), input_shape=(channel, img_rows, img_cols)))\n",
    "    #first convolutional layer, the network has to learn 64 filters with size 3x3 along the input depth (3) \n",
    "    #each one of the 64 filters has bias, so the total number of parameters is: 64*3*3*3 + 64 = 1792\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu', name = 'block1_conv1'))\n",
    "    \n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    #second convolutional layer, the network has to learn 64 filters with size 3x3 along the input depth (3) \n",
    "    #each one of the 64 filters has bias, so the total number of parameters is: 64*3*3*3 + 64 = 1792\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu', name ='block1_conv2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    #2\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    #third convolutional layer, the network has to learn 128 filters with size 3x3 along the input depth (3) \n",
    "    #each one of the 128 filters has bias, so the total number of parameters is: 128*3*3*3 + 128 = 3584\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu', name ='block2_conv1'))\n",
    "    \n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    #fourth convolutional layer, the network has to learn 128 filters with size 3x3 along the input depth (3) \n",
    "    #each one of the 128 filters has bias, so the total number of parameters is: 128*3*3*3 + 128 = 3584\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu', name ='block2_conv2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), dim_ordering=\"th\"))\n",
    "\n",
    "    #3\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu', name ='block3_conv1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu', name ='block3_conv2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu', name ='block3_conv3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), dim_ordering=\"th\"))\n",
    "\n",
    "    #6\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name ='block4_conv1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name ='block4_conv2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name ='block4_conv3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), dim_ordering=\"th\"))\n",
    "\n",
    "    #7\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name ='block5_conv1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name ='block5_conv2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name ='block5_conv3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), dim_ordering=\"th\"))\n",
    "\n",
    "    # Add Fully Connected Layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "    # Loads ImageNet pre-trained data\n",
    "    model.load_weights('vgg16_weights.h5')\n",
    "\n",
    "    # Truncate and replace softmax layer for transfer learning\n",
    "    model.layers.pop()\n",
    "    model.outputs = [model.layers[-1].output]\n",
    "    model.layers[-1].outbound_nodes = []\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Uncomment below to set the first 10 layers to non-trainable (weights will not be updated)\n",
    "    for layer in model.layers[:10]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Learning rate is changed to 0.001\n",
    "    sgd = SGD(lr=1e-6, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])#,f1])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dxB6vBLHvAGt"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "\n",
    "num_train_samples = 0\n",
    "num_valid_samples = 0\n",
    "num_classes = 2\n",
    "\n",
    "def grayscale(img):\n",
    "    # We need to normalize our values between 1 and -1\n",
    "    R = np.max(np.abs(img[:,:,0]))\n",
    "    G = np.max(np.abs(img[:,:,1]))\n",
    "    B = np.max(np.abs(img[:,:,2]))\n",
    "    \n",
    "    BlackMax = 0.2125*R + 0.7154*G + 0.0721*B\n",
    "    img[:,:,0] /= R\n",
    "    img[:,:,1] /= G\n",
    "    img[:,:,2] /= B\n",
    "    \n",
    "    return rgb2gray(img)*BlackMax\n",
    "\n",
    "def normalise(img, color):\n",
    "    mean_pixel = [103.939, 116.779, 123.68] # These values are obtained from the pretrained model\n",
    "    img = img.astype(np.float32, copy=False)\n",
    "    for c in range(3):\n",
    "        img[:, :, c] = img[:, :, c] - mean_pixel[c]\n",
    "    img = img.transpose((2,0,1))\n",
    "    #img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    if(color):\n",
    "        return img\n",
    "    \n",
    "    else:\n",
    "        return grayscale(img)\n",
    "\n",
    "def load_image_data(openClusters, globularClusters,channel):\n",
    "    percentTrain = 0.8\n",
    "    percentValidation = 0.1\n",
    "    percentTest = 0.1\n",
    "    \n",
    "    # Toggle color /grayscale\n",
    "    if(channel == 3):\n",
    "        color = True\n",
    "    if(channel == 1):\n",
    "        color = False\n",
    "    \n",
    "    X_train = []\n",
    "    Y_train =  []\n",
    "    X_validation =  []\n",
    "    Y_validation =  []\n",
    "    X_test =  []\n",
    "    Y_test =  []\n",
    "    \n",
    "    # Separate open clusters into train, validation, test\n",
    "    for (i,img) in enumerate(openClusters):\n",
    "        # Include open clusters in training set\n",
    "        if(i < len(openClusters)*percentTrain):\n",
    "            X_train.append(normalise(img,color))\n",
    "            Y_train.append(0)\n",
    "            \n",
    "        # Include open clusters in validation set\n",
    "        if(i >= len(openClusters)*percentTrain and i < len(openClusters)*(percentTrain+percentValidation)):\n",
    "            X_validation.append(normalise(img,color))\n",
    "            Y_validation.append(0)\n",
    "        \n",
    "        # Include open clusters in validation set\n",
    "        if(i >= len(openClusters)*(percentTrain+percentValidation) and i <= len(openClusters)*(percentTrain+percentValidation + percentTest)):\n",
    "            X_test.append(normalise(img,color))\n",
    "            Y_test.append(0)\n",
    "    \n",
    "    # Separate globular clusters into train, validation, test\n",
    "    for (i,img) in enumerate(globularClusters):\n",
    "        # Include open clusters in training set\n",
    "        if(i < len(globularClusters)*percentTrain):\n",
    "            X_train.append(normalise(img,color))\n",
    "            Y_train.append(1)\n",
    "            \n",
    "        # Include open clusters in validation set\n",
    "        if(i >= len(globularClusters)*percentTrain and i < len(globularClusters)*(percentTrain+percentValidation)):\n",
    "            X_validation.append(normalise(img,color))\n",
    "            Y_validation.append(1)\n",
    "        \n",
    "        # Include open clusters in validation set\n",
    "        if(i >= len(globularClusters)*(percentTrain+percentValidation) and i <= len(globularClusters)*(percentTrain+percentValidation + percentTest)):\n",
    "            X_test.append(normalise(img,color))\n",
    "            Y_test.append(1)\n",
    "    \n",
    "    X_train = np.asarray(X_train,dtype = 'uint8')\n",
    "    X_validation = np.asarray(X_validation,dtype = 'uint8')\n",
    "    X_test = np.asarray(X_test,dtype = 'uint8')\n",
    "    Y_train = np.asarray(Y_train,dtype = 'int')\n",
    "    Y_validation = np.asarray(Y_validation,dtype = 'int')\n",
    "    Y_test = np.asarray(Y_test,dtype = 'int')\n",
    "    \n",
    "    Y_train = np_utils.to_categorical(Y_train,num_classes)\n",
    "    Y_validation = np_utils.to_categorical(Y_validation,num_classes)\n",
    "    Y_test = np_utils.to_categorical(Y_test,num_classes)\n",
    "    \n",
    "    return X_train, Y_train, X_validation, Y_validation, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nHuL-PNlvAG5"
   },
   "outputs": [],
   "source": [
    "filename = 'OpC.h5'\n",
    "openClustersH5 = h5py.File(filename, 'r')\n",
    "nImages = 4000\n",
    "openClusters = [openClustersH5.get(\"image\"+str(i))[:] for i in range(0,nImages)]\n",
    "openClustersH5.close()\n",
    "\n",
    "filename = 'GlCl.h5'\n",
    "globularClustersH5 = h5py.File(filename, 'r')\n",
    "nImages = 4000\n",
    "globularClusters = [globularClustersH5.get(\"image\"+str(i))[:] for i in range(0,nImages)]\n",
    "globularClustersH5.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot model loss, accuracy and f1 in terms of epoch\n",
    "def plotProgress(history):\n",
    "    # list all data in history\n",
    "    print(history.history.keys())\n",
    "    \n",
    "    \n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jsgrafix26/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), name=\"block1_conv1\", activation=\"relu\")`\n",
      "/home/jsgrafix26/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), name=\"block1_conv2\", activation=\"relu\")`\n",
      "/home/jsgrafix26/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), name=\"block2_conv1\", activation=\"relu\")`\n",
      "/home/jsgrafix26/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), name=\"block2_conv2\", activation=\"relu\")`\n",
      "/home/jsgrafix26/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:37: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), strides=(2, 2), data_format=\"channels_first\")`\n",
      "/home/jsgrafix26/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:41: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"block3_conv1\", activation=\"relu\")`\n",
      "/home/jsgrafix26/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:43: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"block3_conv2\", activation=\"relu\")`\n",
      "/home/jsgrafix26/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:45: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"block3_conv3\", activation=\"relu\")`\n",
      "/home/jsgrafix26/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:46: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), strides=(2, 2), data_format=\"channels_first\")`\n",
      "/home/jsgrafix26/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), name=\"block4_conv1\", activation=\"relu\")`\n",
      "/home/jsgrafix26/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:52: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), name=\"block4_conv2\", activation=\"relu\")`\n",
      "/home/jsgrafix26/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:54: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), name=\"block4_conv3\", activation=\"relu\")`\n",
      "/home/jsgrafix26/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:55: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), strides=(2, 2), data_format=\"channels_first\")`\n",
      "/home/jsgrafix26/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:59: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), name=\"block5_conv1\", activation=\"relu\")`\n",
      "/home/jsgrafix26/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:61: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), name=\"block5_conv2\", activation=\"relu\")`\n",
      "/home/jsgrafix26/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:63: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), name=\"block5_conv3\", activation=\"relu\")`\n",
      "/home/jsgrafix26/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:64: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), strides=(2, 2), data_format=\"channels_first\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding2d_1 (ZeroPaddin (None, 3, 226, 226)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 224, 224)      1792      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 64, 226, 226)      0         \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 224, 224)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 112, 112)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 64, 114, 114)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 112, 112)     73856     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 128, 114, 114)     0         \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 112, 112)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 128, 56, 56)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 128, 58, 58)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 256, 56, 56)       295168    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPaddin (None, 256, 58, 58)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 256, 56, 56)       590080    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPaddin (None, 256, 58, 58)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 256, 56, 56)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 256, 28, 28)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPaddin (None, 256, 30, 30)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 512, 28, 28)       1180160   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPaddin (None, 512, 30, 30)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 512, 28, 28)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPaddi (None, 512, 30, 30)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 512, 28, 28)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 512, 14, 14)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPaddi (None, 512, 16, 16)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 512, 14, 14)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPaddi (None, 512, 16, 16)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 512, 14, 14)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPaddi (None, 512, 16, 16)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 512, 14, 14)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 512, 7, 7)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 2002      \n",
      "=================================================================\n",
      "Total params: 138,359,546\n",
      "Trainable params: 138,099,386\n",
      "Non-trainable params: 260,160\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jsgrafix26/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:27: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 800 samples\n",
      "Epoch 1/40\n",
      "6400/6400 [==============================] - 50s 8ms/step - loss: 0.6934 - acc: 0.4764 - val_loss: 0.6922 - val_acc: 0.5250\n",
      "Epoch 2/40\n",
      "6400/6400 [==============================] - 46s 7ms/step - loss: 0.6921 - acc: 0.5334 - val_loss: 0.6910 - val_acc: 0.5825\n",
      "Epoch 3/40\n",
      "6400/6400 [==============================] - 46s 7ms/step - loss: 0.6913 - acc: 0.5692 - val_loss: 0.6900 - val_acc: 0.6400\n",
      "Epoch 4/40\n",
      "6400/6400 [==============================] - 46s 7ms/step - loss: 0.6904 - acc: 0.6086 - val_loss: 0.6892 - val_acc: 0.6650\n",
      "Epoch 5/40\n",
      "6400/6400 [==============================] - 46s 7ms/step - loss: 0.6899 - acc: 0.6308 - val_loss: 0.6884 - val_acc: 0.6913\n",
      "Epoch 6/40\n",
      "6400/6400 [==============================] - 46s 7ms/step - loss: 0.6890 - acc: 0.6577 - val_loss: 0.6876 - val_acc: 0.7125\n",
      "Epoch 7/40\n",
      "6400/6400 [==============================] - 46s 7ms/step - loss: 0.6885 - acc: 0.6723 - val_loss: 0.6868 - val_acc: 0.7438\n",
      "Epoch 8/40\n",
      "2368/6400 [==========>...................] - ETA: 27s - loss: 0.6880 - acc: 0.6875"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Example to fine-tune on 3000 samples from Cifar10\n",
    "\n",
    "    img_rows, img_cols = 224, 224 # Resolution of inputs\n",
    "    channel = 3\n",
    "    num_classes = 2\n",
    "    batch_size = 16\n",
    "    #10\n",
    "    nb_epoch = 40\n",
    "\n",
    "    # Load Cifar10 data. Please implement your own load_data() module for your own dataset\n",
    "    X_train, Y_train, X_valid, Y_valid , X_test, Y_test = load_image_data(openClusters, globularClusters, channel = channel)\n",
    "\n",
    "    # Load our model\n",
    "    model = vgg16_model(img_rows, img_cols, channel, num_classes)\n",
    "    model.summary()\n",
    "\n",
    "    # Start Fine-tuning\n",
    "    history = model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              nb_epoch=nb_epoch,\n",
    "              shuffle=True,\n",
    "              verbose=1,\n",
    "              validation_data=(X_valid, Y_valid),\n",
    "              )\n",
    "\n",
    "    # Make predictions\n",
    "    predictions_valid = model.predict(X_valid, batch_size=batch_size, verbose=1)\n",
    "\n",
    "    #add grad_cam implementation here \n",
    "    # Cross-entropy loss score\n",
    "    #score = log_loss(Y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay(array1, array2, alpha=0.5):\n",
    "    \"\"\"Overlays `array1` onto `array2` with `alpha` blending.\n",
    "    Args:\n",
    "        array1: The first numpy array.\n",
    "        array2: The second numpy array.\n",
    "        alpha: The alpha value of `array1` as overlayed onto `array2`. This value needs to be between [0, 1],\n",
    "            with 0 being `array2` only to 1 being `array1` only (Default value = 0.5).\n",
    "    Returns:\n",
    "        The `array1`, overlayed with `array2` using `alpha` blending.\n",
    "    \"\"\"\n",
    "    if alpha < 0. or alpha > 1.:\n",
    "        raise ValueError(\"`alpha` needs to be between [0, 1]\")\n",
    "    if array1.shape != array2.shape:\n",
    "        raise ValueError('`array1` and `array2` must have the same shapes')\n",
    "\n",
    "    return (array1 * alpha + array2 * (1. - alpha)).astype(array1.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "from vis.visualization import visualize_cam\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "glIndices = [0,2]\n",
    "opIndices = [21,24]\n",
    "\n",
    "for modifier in [None]:#, 'guided', 'relu']:\n",
    "    plt.figure(figsize = (20,90))\n",
    "    f, ax = plt.subplots(1,5)\n",
    "    #plt.suptitle(\"vanilla\" if modifier is None else modifier)\n",
    "    for i in range(5):\n",
    "        img = openClusters[i+25]\n",
    "        grads = visualize_cam(model, layer_idx=-1, filter_indices=0,\n",
    "                                  seed_input=img, backprop_modifier=modifier)\n",
    "        jet_heatmap = np.uint8(cm.jet(grads)[..., :3] * 255)\n",
    "#         print(np.shape(img))\n",
    "#         print(np.shape(jet_heatmap))\n",
    "#         print(i)\n",
    "        #x = np.zeros(jet_heatmap)\n",
    "        #result = [:,:,:,0]\n",
    "        ax[i].imshow(overlay(jet_heatmap[:,:,:,0],img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = openClusters[21]\n",
    "grads = visualize_cam(model, layer_idx=-1, filter_indices=0,\n",
    "                          seed_input=img, backprop_modifier=modifier)\n",
    "jet_heatmap = np.uint8(cm.jet(grads)[..., :3] * 255)\n",
    "o1im = img\n",
    "o1 = overlay(jet_heatmap[:,:,:,0],img)\n",
    "\n",
    "img = openClusters[24]\n",
    "grads = visualize_cam(model, layer_idx=-1, filter_indices=0,\n",
    "                          seed_input=img, backprop_modifier=modifier)\n",
    "jet_heatmap = np.uint8(cm.jet(grads)[..., :3] * 255)\n",
    "o2im = img\n",
    "o2 = overlay(jet_heatmap[:,:,:,0],img)\n",
    "\n",
    "img = globularClusters[0]\n",
    "grads = visualize_cam(model, layer_idx=-1, filter_indices=0,\n",
    "                          seed_input=img, backprop_modifier=modifier)\n",
    "jet_heatmap = np.uint8(cm.jet(grads)[..., :3] * 255)\n",
    "g1im = img\n",
    "g1 = overlay(jet_heatmap[:,:,:,0],img)\n",
    "\n",
    "img = globularClusters[2]\n",
    "grads = visualize_cam(model, layer_idx=-1, filter_indices=0,\n",
    "                          seed_input=img, backprop_modifier=modifier)\n",
    "jet_heatmap = np.uint8(cm.jet(grads)[..., :3] * 255)\n",
    "g2im = img\n",
    "g2 = overlay(jet_heatmap[:,:,:,0],img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 4)\n",
    "fig.set_size_inches(22,12)\n",
    "\n",
    "ax[0,0].imshow(o1im)\n",
    "ax[0,0].set_title('Original open cluster', size = 22)\n",
    "ax[0,0].tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    left = False,\n",
    "    right = False,\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False,\n",
    "    labelleft = False) # labels along the bottom edge are off\n",
    "\n",
    "ax[0,1].imshow(o2im)\n",
    "ax[0,1].set_title('Original open cluster', size = 22)\n",
    "ax[0,1].tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    left = False,\n",
    "    right = False,\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False,\n",
    "    labelleft = False) # labels along the bottom edge are off\n",
    "\n",
    "ax[0,2].imshow(g1im)\n",
    "ax[0,2].set_title('Original globular cluster', size = 22)\n",
    "ax[0,2].tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    left = False,\n",
    "    right = False,\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False,\n",
    "    labelleft = False) # labels along the bottom edge are off\n",
    "\n",
    "ax[0,3].imshow(g2im)\n",
    "ax[0,3].set_title('Original globular cluster', size = 22)\n",
    "ax[0,3].tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    left = False,\n",
    "    right = False,\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False,\n",
    "    labelleft = False) # labels along the bottom edge are off\n",
    "\n",
    "\n",
    "ax[1,0].imshow(o1)\n",
    "ax[1,0].set_title('VGG16 heat map', size = 22)\n",
    "ax[1,0].tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    left = False,\n",
    "    right = False,\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False,\n",
    "    labelleft = False) # labels along the bottom edge are off\n",
    "\n",
    "ax[1,1].imshow(o2)\n",
    "ax[1,1].set_title('VGG16 heat map', size = 22)\n",
    "ax[1,1].tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    left = False,\n",
    "    right = False,\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False,\n",
    "    labelleft = False) # labels along the bottom edge are off\n",
    "\n",
    "ax[1,2].imshow(g1)\n",
    "ax[1,2].set_title('VGG16 heat map', size = 22)\n",
    "ax[1,2].tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    left = False,\n",
    "    right = False,\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False,\n",
    "    labelleft = False) # labels along the bottom edge are off\n",
    "\n",
    "ax[1,3].imshow(g2)\n",
    "ax[1,3].set_title('VGG16 heat map', size = 22)\n",
    "ax[1,3].tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    left = False,\n",
    "    right = False,\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False,\n",
    "    labelleft = False) # labels along the bottom edge are off\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/42763094/how-to-save-final-model-using-keras\n",
    "# keras library import  for Saving and loading model and weights\n",
    "\n",
    "\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "\n",
    "# serialize model to JSON\n",
    "#  the keras model which is trained is defined as 'model' in this example\n",
    "model_json = model.to_json()\n",
    "\n",
    "\n",
    "with open(\"model_num.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_num.h5\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "VGGImplementation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
